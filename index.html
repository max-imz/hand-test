<!DOCTYPE html>
<html lang="fr">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Détection Main Pro - Fond Noir</title>
  <style>
    /* Reset et style général */
    *, *::before, *::after {
      box-sizing: border-box;
    }
    body, html {
      margin: 0; padding: 0;
      height: 100vh;
      background-color: #111; /* fond noir */
      color: #eee;
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      user-select: none;
      overflow: hidden;
    }
    h1 {
      margin: 0 0 1rem;
      font-weight: 600;
      font-size: 1.8rem;
      letter-spacing: 0.05em;
      text-align: center;
      color: #0ff;
      text-shadow: 0 0 10px #0ff;
    }
    #container {
      position: relative;
      width: 640px;
      max-width: 95vw;
      aspect-ratio: 4 / 3;
      background: #111; /* fond noir */
      border-radius: 12px;
      box-shadow: 0 0 25px #0ff88a;
      overflow: hidden;
    }
    video, canvas {
      position: absolute;
      top: 0; left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      transform: scaleX(-1);
      border-radius: 12px;
      user-select: none;
      pointer-events: none;
    }
    #status {
      margin-top: 1rem;
      font-size: 1.1rem;
      color: #0ff;
      font-weight: 500;
      font-family: monospace;
      user-select: text;
      text-shadow: 0 0 5px #0ff;
    }
  </style>
</head>
<body>
  <h1>Détection Main Pro - Fond Noir</h1>
  <div id="container">
    <video id="video" autoplay playsinline muted></video>
    <canvas id="canvas"></canvas>
  </div>
  <div id="status">Initialisation...</div>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@4.9.0/dist/tf-core.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@4.9.0/dist/tf-converter.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose@0.0.7/dist/handpose.min.js"></script>

  <script>
    (async () => {
      const status = document.getElementById('status');
      const video = document.getElementById('video');
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');

      canvas.width = 640;
      canvas.height = 480;

      const logStatus = (msg) => {
        status.textContent = msg;
        console.log(msg);
      };

      async function setupCamera() {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            video: { facingMode: 'user', width: 640, height: 480 },
            audio: false
          });
          video.srcObject = stream;
          return new Promise((resolve) => {
            video.onloadedmetadata = () => {
              video.play();
              resolve();
            };
          });
        } catch (err) {
          logStatus('Erreur accès caméra : ' + err.message);
          throw err;
        }
      }

      async function loadModel() {
        logStatus('Chargement modèle...');
        const model = await handpose.load({
          detectionConfidence: 0.8,
          maxContinuousChecks: 10,
        });
        logStatus('Modèle chargé, prêt à détecter.');
        return model;
      }

      const connections = [
        [0,1],[1,2],[2,3],[3,4],       // Pouce
        [0,5],[5,6],[6,7],[7,8],       // Index
        [0,9],[9,10],[10,11],[11,12],  // Majeur
        [0,13],[13,14],[14,15],[15,16],// Annulaire
        [0,17],[17,18],[18,19],[19,20] // Auriculaire
      ];

      function drawKeypoints(keypoints) {
        ctx.fillStyle = '#0ff';
        ctx.strokeStyle = '#08b';
        ctx.lineWidth = 2;
        keypoints.forEach(point => {
          const [x, y] = point;
          ctx.beginPath();
          ctx.arc(x, y, 6, 0, 2 * Math.PI);
          ctx.fill();
          ctx.stroke();
        });
      }

      function drawConnections(keypoints) {
        ctx.strokeStyle = '#08b';
        ctx.lineWidth = 3;
        connections.forEach(([start, end]) => {
          const [x1, y1] = keypoints[start];
          const [x2, y2] = keypoints[end];
          ctx.beginPath();
          ctx.moveTo(x1, y1);
          ctx.lineTo(x2, y2);
          ctx.stroke();
        });
      }

      async function detectHands(model) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        try {
          const predictions = await model.estimateHands(video, true);

          if (predictions.length > 0) {
            predictions.forEach(prediction => {
              drawConnections(prediction.landmarks);
              drawKeypoints(prediction.landmarks);
            });
            logStatus('Main détectée');
          } else {
            logStatus('Aucune main détectée');
          }
        } catch (err) {
          logStatus('Erreur détection : ' + err.message);
        }
        requestAnimationFrame(() => detectHands(model));
      }

      try {
        await setupCamera();
        const model = await loadModel();
        detectHands(model);
      } catch (err) {
        logStatus('Erreur initialisation : ' + err.message);
      }
    })();
  </script>
</body>
</html>
